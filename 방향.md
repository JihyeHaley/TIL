연속된   show ->

긴 sequence -> 직접 활용하기 보다는 hierechy를 쓴다는 등의 모델링이 필요.

coincetence 를 측정할 수 있는 metric이 있고 없고가 아직 없다.



## 방향

**도메인**을 세분화해서 번역

1. segment align 이 잘 맞으니깐
   * 필터링: 아마추어가 한거라서 그닥 정확하지 않다.
   * 토크쇼나 특정 프로그램에서는 정확도를 높일 수 있다는 **가정**
2. 데이터 학습 품질을 전문가를 통해 정제시켜놓자.
3. 구어체를 처리했으니깐, 문어체로 실험했을 때 정확도가 높을지 알고싶다.



이전의 문장을 참고하면서 보니깐... 오류 많았따. (정확하지 않았던 문장)
**개선점 :** *참고할 만한 대화인지 아닌지 확인을 해봐야한다. **배경**에 대한 판단을 해야한다.* 

가정 : 문장 < 문단 < --- 
학습할 수 있는 SBS의 데이터를 대량으로 받았다. / 영상자막번역 회사가 제공

테스트 데이터를 갖고, 먼저 모델로 테스트를...



Text sample을 더 늘리는건...!!! 샘플의 양은 어느정도로? 현재는 2-3000개 정도 (2-5가지) 1,000개, 5가지

블루가 평가하는걸 

**automatic post tag** 를 transformer

**SBS : 영상번역에서는 timestamp를 줄여서 : 하나의 문장을 풀번역을 했을 때 문장 자체가 길어길 수 있기 때문에 한 화면에 들어갈 수 있도록 주어를 자르다던가, 용어를 바꿔치기 한다던가 등의 것들이 필요로 하다.**

**한국 => 영어**

**알타이어족 중심**으로  -> zero shot - 



*cf*. 존댓말을 하는데에서는 화자간의 관계에 따라서 달라질 수 있으니깐, 

박사님 idea: 화자의 활용에 따라서가 아니라 모든 것을 다 존댓말로 표현 하면 어떨까?

튜닝... 



tag를 가지고 스페셜 토큰을 한다 한들 .. 어떤식으로 해야할지에 관련된 인사이트가 아니라...
1차적으로 나온 결과 자체가 흐린해서 어떻게 수정을 해야할지 





번역기가 . 번역 사전을 포함한 경우가 없는데,  지콘은 사전이 있다. AutoML 